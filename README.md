# NumeriAI - Full-Stack LLM Web App

A complete production-ready full-stack AI application demonstrating a minimal transformer-based LLM for mathematical Q&A tasks.

## ğŸ¯ Project Overview

NumeriAI is a full-stack implementation featuring:
- **Backend**: FastAPI + PyTorch transformer model
- **Frontend**: React + Vite + Tailwind CSS
- **Training**: PyTorch-based model trainer
- **Deployment**: Docker support for both backend and frontend

## ğŸ“ Project Structure

```
â”œâ”€â”€ backend/                      # FastAPI backend with PyTorch
â”‚   â”œâ”€â”€ main.py                   # FastAPI application
â”‚   â”œâ”€â”€ inference.py              # Model inference logic
â”‚   â”œâ”€â”€ model.py                  # TinyTransformer model
â”‚   â”œâ”€â”€ tokenizer.py              # Character-level tokenizer
â”‚   â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile                # Docker configuration
â”‚   â””â”€â”€ checkpoints/
â”‚       â””â”€â”€ model.pt              # Trained model weights
â”‚
â”œâ”€â”€ frontend/                     # React frontend
â”‚   â”œâ”€â”€ index.html                # HTML entry point
â”‚   â”œâ”€â”€ package.json              # Node dependencies
â”‚   â”œâ”€â”€ vite.config.js            # Vite configuration
â”‚   â”œâ”€â”€ tailwind.config.js        # Tailwind configuration
â”‚   â”œâ”€â”€ postcss.config.js         # PostCSS configuration
â”‚   â”œâ”€â”€ Dockerfile                # Docker configuration
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx               # Main React component
â”‚       â”œâ”€â”€ main.jsx              # React entry point
â”‚       â”œâ”€â”€ api.js                # Backend API client
â”‚       â””â”€â”€ index.css             # Tailwind styles
â”‚
â””â”€â”€ training/                     # Model training
    â”œâ”€â”€ train.py                  # Training script
    â”œâ”€â”€ model.py                  # Model definition
    â”œâ”€â”€ tokenizer.py              # Tokenizer definition
    â””â”€â”€ dataset.txt               # Training dataset
```

## ğŸš€ Quick Start

### 1. Train the Model

```bash
cd training
python train.py
```

This will generate `../backend/checkpoints/model.pt`.

### 2. Run Backend Server

```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

The backend will be available at `http://localhost:8000`.

### 3. Run Frontend

```bash
cd frontend
npm install
npm run dev
```

The frontend will be available at `http://localhost:5173`.

## ğŸ³ Docker Deployment

### Backend Docker

```bash
cd backend
docker build -t numeriai-backend .
docker run -p 8000:8000 numeriai-backend
```

### Frontend Docker

```bash
cd frontend
docker build -t numeriai-frontend .
docker run -p 80:80 numeriai-frontend
```

## ğŸ”§ Technology Stack

### Backend
- **Framework**: FastAPI
- **Server**: Uvicorn
- **ML**: PyTorch
- **Python**: 3.9+

### Frontend
- **Library**: React 18.2.0
- **Build Tool**: Vite
- **Styling**: Tailwind CSS
- **Node**: 18+

### Training
- **Framework**: PyTorch
- **Model**: Tiny Transformer (32 embedding size, 2 heads, 2 layers)
- **Tokenizer**: Character-level tokenizer

## ğŸ“Š Model Architecture

The TinyTransformer model uses:
- **Embedding Size**: 32
- **Attention Heads**: 2
- **Hidden Dimension**: 64
- **Layers**: 2
- **Max Sequence Length**: 32
- **Vocabulary**: Digits (0-9) + Math operators (+-*/) + Space

## ğŸ® Usage

1. Enter a math problem in the frontend (e.g., "2+3")
2. Click "Send"
3. The model generates the answer

### Example Queries
- `2+3` â†’ `5`
- `7-2` â†’ `5`
- `4*2` â†’ `8`
- `9/3` â†’ `3`

## ğŸ“‹ API Endpoints

### POST /generate

Request:
```json
{
  "prompt": "2+3"
}
```

Response:
```json
{
  "answer": "5"
}
```

## ğŸ› ï¸ Development

### Backend Setup
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Frontend Setup
```bash
cd frontend
npm install
npm run dev    # Development server
npm run build  # Production build
```

### Training
```bash
cd training
python train.py
```

## ğŸ“¦ Dependencies

### Backend (`backend/requirements.txt`)
- fastapi
- uvicorn
- torch

### Frontend (`frontend/package.json`)
- react
- react-dom
- vite
- tailwindcss
- postcss
- autoprefixer

## ğŸ” Security Notes

- CORS is enabled for all origins in development (update in production)
- Model runs on CPU only (suitable for development/testing)

## ğŸš¢ Production Deployment

For production deployment:
1. Update CORS settings in `backend/main.py`
2. Add environment variables for configuration
3. Use a production-grade ASGI server (e.g., Gunicorn + Uvicorn)
4. Deploy frontend behind Nginx or CDN
5. Use proper model versioning and checkpointing

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ‘¤ Author

Pawan Vuppu (@pawanvuppu01)

## ğŸ¤ Contributing

Feel free to fork, submit issues, and create pull requests!

---

**Last Updated**: November 28, 2025
